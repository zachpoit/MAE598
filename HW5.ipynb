{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 5\n",
    "\n",
    "#### Question 1\n",
    "\n",
    "Wrote my own QP Sub Problem Solver using the active set strategy. Its not beautiful, but it works.\n",
    "\n",
    "$ f = x_1^2 + (x_2 - 3)^2$\n",
    "\n",
    "$g_1 = x_2^2 - 2 x_1$\n",
    "\n",
    "$g_2 = (x_2-1)^2 + 5x_1 - 15$\n",
    "\n",
    "$ L = f + \\mu_1 g_1 + \\mu_2 g_2$\n",
    "\n",
    "$L = x_1^2 + (x_2 - 3)^2 + \\mu_1 (x_2^2 - 2 x_1) + \\mu_2((x_2-1)^2 + 5x_1 - 15)$\n",
    "\n",
    "$ L = x_1^2 + (x_2 - 3)^2 + \\mu_1 x_2^2 - \\mu_1 2 x_1 + \\mu_2(x_2-1)^2 + \\mu_2 5x_1 - \\mu_2 15 $ \n",
    "\n",
    "$\\nabla L = \\begin{bmatrix} 2 x_1 - 2 \\mu_1 + 5 \\mu_2\\\\ 2(x_2 -3) + 2 \\mu_1 x_2 + 2 \\mu_2(x_1 - 1)\\end{bmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1.375 1.625]\n",
      "x: [1.06726031 1.45244865]\n",
      "x: [1.05188265 1.45043764]\n",
      "x: [1.05188265 1.45043764]\n",
      "x: [1.05851064 1.45500728]\n",
      "x: [1.0602401  1.45619588]\n",
      "x: [1.06019991 1.45616824]\n",
      "x: [1.06020079 1.45616881]\n",
      "x: [1.06020081 1.45616875]\n",
      "x: [1.06020081 1.45616875]\n",
      "x: [1.0602008  1.45616874]\n",
      "x: [1.0602008  1.45616874]\n",
      "x: [1.0602008  1.45616874]\n",
      "x: [1.0602008  1.45616873]\n",
      "x: [1.06020081 1.45616873]\n",
      "f(x): 3.5074407455549412\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = x1^2 + (x2 - 3)^2\n",
    "\n",
    "# g1 = x2^2 - 2 x1\n",
    "# g2 = (x2-1)^2 + 5x1 - 15\n",
    "\n",
    "t = 0.3\n",
    "\n",
    "# function for evaluating f at x\n",
    "def f(x):\n",
    "    return (x[0] ** 2 + (x[1] - 3) ** 2)\n",
    "\n",
    "# function for evaluating g1 and g2 at x\n",
    "def g(x):\n",
    "    g = np.zeros([2,1])\n",
    "    g[0] = x[1]**2 - 2 * x[0]\n",
    "    g[1] = (x[1] - 1) ** 2 + 5 * x[0] - 15\n",
    "    return g\n",
    "\n",
    "# function for evaluating the gradiant of L at x and mu\n",
    "def gradL(x,mu): \n",
    "    gradL = np.zeros([1,2])\n",
    "    gradL[0,0] = 2*x[0] - 2*mu[0] + 5*mu[1]\n",
    "    gradL[0,1] = 2*(x[1] - 3) + 2 * mu[0] * x[1] + 2 * mu[1] * (x[0] - 1)\n",
    "    return gradL\n",
    "\n",
    "# function for evaluating the partial derivative of f with respect to x\n",
    "def dfdx(x):\n",
    "    fx = np.zeros([2,1])\n",
    "    fx[0] = 2*x[0]\n",
    "    fx[1] = 2*(x[1] - 3)\n",
    "    return fx\n",
    "\n",
    "# function for evaluating the partial derivative of the g's with respect to x\n",
    "def pgpx(x): \n",
    "    pgpx = np.zeros([2,2])\n",
    "    pgpx[0,0] = -2\n",
    "    pgpx[0,1] = 2*x[1]\n",
    "    pgpx[1,0] = 5\n",
    "    pgpx[1,1] = 2*(x[1] - 1)\n",
    "    return pgpx\n",
    "\n",
    "# function for solving the QP subproblem, uses the active set strategy that was gone over in class\n",
    "# gets an empty A, and h because there are no equality constraints. \n",
    "def QPSub(W,A,Aorder,constraints,h,x,fx,mu,jstar):\n",
    "    O = np.zeros([constraints,constraints])\n",
    "\n",
    "    n2L = np.bmat([[W, A.T],[A,O]]) # Z in Zx = y\n",
    "    fxh = np.bmat([[-fx],[-h]]) # Z in Zx = y\n",
    "\n",
    "    slambda = np.linalg.solve(n2L,fxh) # use lin alg to solve Zx = y\n",
    "    lambdamu = slambda[2:] # seperate the mu's \n",
    "    s = slambda[:2] # seperate the s \n",
    "\n",
    "    grad_cond = np.matmul(pgpx(x),s) + g(x) # determine the condition for adding to A matrix\n",
    "    if constraints == 0: # if there are no constraints in A and h then we don't need to check the mu\n",
    "        if all(grad_cond <= 0): # leave condition\n",
    "            return slambda, Aorder,constraints\n",
    "        else:\n",
    "            # do the add to A scenario\n",
    "            jstar = np.argmax(grad_cond)\n",
    "            Aprime = pgpx(x)[jstar]\n",
    "            A = np.vstack((A,Aprime))\n",
    "            h = np.vstack((h,g(x)[jstar]))\n",
    "            Aorder = np.vstack((Aorder,jstar))\n",
    "            \n",
    "            ind = np.argsort(Aorder, axis=0)\n",
    "            Aorder = np.take_along_axis(Aorder, ind, axis=0)\n",
    "            A = np.take_along_axis(A, ind, axis=0)\n",
    "            h = np.take_along_axis(h,ind,axis=0)\n",
    "\n",
    "            constraints += 1\n",
    "\n",
    "            # recursion to continue to modify the A matrix and recalculate Zx=y\n",
    "            return QPSub(W,A,Aorder,constraints,h,x,fx,mu,jstar)\n",
    "        \n",
    "    else: # there are constraints in A and hso we do need to check the mu\n",
    "        if all(lambdamu > 0) and all(grad_cond <= 0): # leave condition\n",
    "\n",
    "            return slambda, Aorder, constraints\n",
    "\n",
    "        elif all(lambdamu < 0): \n",
    "            # do the remove from A scenario\n",
    "            istar = np.argmin(lambdamu)\n",
    "            A = np.delete(A, istar, 0)\n",
    "            Aorder = np.delete(Aorder,istar,0)\n",
    "            h = np.delete(h,istar,0)\n",
    "\n",
    "            constraints -= 1\n",
    "            \n",
    "            # recursion to continue to modify the A matrix and recalculate Zx=y\n",
    "            return QPSub(W,A,Aorder,constraints,h,x,fx,mu,jstar)\n",
    "\n",
    "        elif all(grad_cond >= 0):\n",
    "            # do the add to A scenario\n",
    "            jstar = np.argmax(grad_cond)\n",
    "            Aprime = pgpx(x)[jstar]\n",
    "            A = np.vstack((A,Aprime))\n",
    "            h = np.vstack((h,g(x)[jstar]))\n",
    "            Aorder = np.vstack((Aorder,jstar))\n",
    "\n",
    "            ind = np.argsort(Aorder, axis=0)\n",
    "            Aorder = np.take_along_axis(Aorder, ind, axis=0)\n",
    "            A = np.take_along_axis(A, ind, axis=0)\n",
    "            h = np.take_along_axis(h,ind,axis=0)\n",
    "\n",
    "            constraints += 1\n",
    "\n",
    "            # recursion to continue to modify the A matrix and recalculate Zx=y\n",
    "            return QPSub(W,A,Aorder,constraints,h,x,fx,mu,jstar)\n",
    "\n",
    "# BIG F for linesearch, used in calculation for f_alpha and phi_alpha\n",
    "# merit function\n",
    "def big_F(x,weights):\n",
    "    arr = g(x)\n",
    "\n",
    "    arr[arr < 0] = 0\n",
    "\n",
    "    return f(x) + np.matmul(weights,arr)\n",
    "    \n",
    "# dFdalpha for calculating phi_alpha\n",
    "# similar to merit function, derivative of it with respect to alpha\n",
    "def dFdalpha(x,s,weights):\n",
    "    arr = g(x)\n",
    "\n",
    "    arr3 = np.matmul(pgpx(x),s)\n",
    "    \n",
    "    arr3[arr<=0] = 0\n",
    "\n",
    "    return np.matmul(dfdx(x).T,s) + np.matmul(weights,arr3)\n",
    "    \n",
    "    \n",
    "# Linesearch to calculate the new alpha\n",
    "# uses weights to for the merit function\n",
    "def linesearch(x,alpha,s,mu,weights):\n",
    "    weights = np.max(np.array([mu,0.5*(weights + mu)]),0)\n",
    "    arr = x+alpha*s.T\n",
    "    f_alpha = big_F(arr.T,weights)\n",
    "    phi_alpha = big_F(x,weights) + t*alpha*dFdalpha(x,s,weights)\n",
    "    \n",
    "    while f_alpha > phi_alpha:\n",
    "        alpha *= 0.5\n",
    "        arr = x+alpha*s.T\n",
    "        f_alpha = big_F(arr.T,weights)\n",
    "        \n",
    "        phi_alpha = big_F(x,weights) + t*alpha*dFdalpha(x,s,weights)\n",
    "    return alpha,weights\n",
    "\n",
    "\n",
    "x = np.array([1.,1.]) # intial condtions\n",
    "mu = np.array([0.001,0.001]) # intial slightly greater than zero mu's to avoid singular matrix error\n",
    "\n",
    "W = np.eye(2) # intial matrix\n",
    "count = 0 # counter\n",
    "\n",
    "# main loop, calculates gradL every iteration in while statement\n",
    "while np.linalg.norm(gradL(x,mu)) > 0.001 and count < 30:\n",
    "    constraints = 0\n",
    "    # establish some nessecary things for QP sub problem\n",
    "    A = np.zeros([constraints,2])\n",
    "    Aorder = np.zeros([constraints,1])\n",
    "    fx = dfdx(x)\n",
    "    h = np.zeros([constraints,1])\n",
    "\n",
    "    slambda,Aorder,constraints = QPSub(W,A,Aorder,constraints,h,x,fx,mu,-1) # call qpsub and solve it using recursion\n",
    "\n",
    "    s = slambda[:2] # grab s and seperate it\n",
    "\n",
    "    # bad way of updating mu's, but works for now. something to fix for future iterations after the class\n",
    "    if len(Aorder) == 2 or len(Aorder) == 1 and Aorder[0] == 0:\n",
    "        mu[[int(i) for i in list(Aorder.T[0])]] = slambda[2:][[int(i) for i in list(Aorder.T[0])]].flatten()\n",
    "    else:\n",
    "        break # this scenario if continued with breaks the kernal, the mu assignment needs to be rewritten but for now it solves the problem \n",
    "    \n",
    "    # Linsearch\n",
    "    alpha,weights = linesearch(x,1,s,mu,mu)\n",
    "\n",
    "    # BFGS section\n",
    "    xnew = x+ alpha*s.T\n",
    "\n",
    "    xnew = xnew.T\n",
    "\n",
    "    y = g(xnew) - g(x)\n",
    "\n",
    "    W = W + np.matmul(y,y.T)/np.matmul(y.T,s) - np.matmul(np.matmul(W,s),np.matmul(s.T,W.T))/(np.matmul(np.matmul(s.T,W),s))\n",
    "\n",
    "    # update old x with new x and print\n",
    "    count += 1\n",
    "    x[0] = xnew[0]\n",
    "    x[1] = xnew[1]\n",
    "    print('x:',x)\n",
    "\n",
    "print('f(x):',f(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![h function](HW5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "\n",
    "Thrust: $ l = \\alpha$\n",
    "\n",
    "Dynamics: $ f =  \\begin{bmatrix} \\dot{x_1} \\\\ \\dot{x_2} \\\\ \\dot{x_3} \\end{bmatrix} = \\begin{bmatrix} x_2 \\\\ -g + \\frac{\\alpha}{x_3} \\\\ - K \\alpha \\end{bmatrix}$\n",
    "\n",
    "Hamiltonian: $H = -l + \\lambda^T f = -\\alpha + \\lambda_1 \\dot{x_1} + \\lambda_2 \\dot{x_2} + \\lambda_3 \\dot{x_3} = -\\alpha + \\lambda_1 x_2 - \\lambda_2 g + \\lambda_2 \\frac{\\alpha}{x_3} - \\lambda_3 K \\alpha = \\alpha(-1 + \\frac{\\lambda_2}{x_3} - \\lambda_3 K) + \\lambda_1 x_2 - \\lambda_2 g$\n",
    "\n",
    "$\\dot{\\lambda} = -\\frac{\\partial{H}}{\\partial{x}} = -\\begin{bmatrix} \\frac{\\partial{H}}{\\partial{x_1}} \\\\ \\frac{\\partial{H}}{\\partial{x_2}} \\\\ \\frac{\\partial{H}}{\\partial{x_3}} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -\\lambda_1 \\\\ \\frac{\\lambda_2 \\alpha}{x_3^2} \\end{bmatrix}$\n",
    "\n",
    "$b = -1 + \\frac{\\lambda_2}{x_3} - \\lambda_3 K$\n",
    "\n",
    "$\\frac{db}{dt} = \\frac{\\dot{\\lambda_2}x_3 - \\dot{x_3}\\lambda_2}{x_3^2} - \\dot{\\lambda_3} K = \\frac{-\\lambda_1 x_3 + \\lambda_2 K \\alpha}{x_3^2} - \\frac{\\lambda_2 K \\alpha}{x_3^2} = \\frac{-\\lambda_1}{x_3} $\n",
    "\n",
    "Mass is always greater than zero: $x_3 > 0$\n",
    "\n",
    "\n",
    "The $ \\lambda_1 $ value is always constant: $\\dot{\\lambda_1} = 0$\n",
    "\n",
    "If $ \\lambda_1 $ is positive, then $\\frac{db}{dt}$ is always negative. If $ \\lambda_1 $ is negative, then $\\frac{db}{dt}$ is always positive. Thus $b$ is monotonic because it's first derivative never changes signs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac86c4d38455bde037201527a030247e15a8d9273003618bcf52d7fdb27ddaec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
